{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the datasets\n",
    "\n",
    "The path to dataset directory and patterns to search in those directories for the HPC, PFC recordings are loaded from the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phasic_tonic.detect_phasic import detect_phasic\n",
    "from phasic_tonic.DatasetLoader import DatasetLoader\n",
    "from phasic_tonic.helper import get_metadata\n",
    "from phasic_tonic.runtime_logger import logger_setup\n",
    "from phasic_tonic.utils import get_sequences\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pynapple as nap\n",
    "import yasa\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.io import loadmat\n",
    "from mne.filter import resample\n",
    "\n",
    "fs_cbd = 2500\n",
    "fs_os = 2500\n",
    "fs_rgs = 1000\n",
    "\n",
    "targetFs = 500\n",
    "n_down_cbd = fs_cbd/targetFs\n",
    "n_down_rgs = fs_rgs/targetFs\n",
    "n_down_os = fs_os/targetFs\n",
    "\n",
    "logger = logger_setup()\n",
    "\n",
    "CONFIG_DIR = \"/home/nero/phasic_tonic/data/dataset_loading.yaml\"\n",
    "\n",
    "Datasets = DatasetLoader(CONFIG_DIR)\n",
    "mapped_datasets = Datasets.load_datasets()\n",
    "\n",
    "def preprocess(signal: np.ndarray, n_down: int, target_fs=500) -> np.ndarray:\n",
    "    \"\"\"Downsample and remove artifacts.\"\"\"\n",
    "    \n",
    "    logger.debug(\"STARTED: Resampling to 500 Hz.\")\n",
    "    # Downsample to 500 Hz\n",
    "    data = resample(signal, down=n_down, method='fft', npad='auto')\n",
    "    logger.debug(\"FINISHED: Resampling to 500 Hz.\")\n",
    "    logger.debug(\"Resampled: {0} -> {1}.\".format(str(signal.shape), str(data.shape)))\n",
    "    \n",
    "    logger.debug(\"STARTED: Remove artifacts.\")\n",
    "    # Remove artifacts\n",
    "    art_std, _ = yasa.art_detect(data, target_fs , window=1, method='std', threshold=4)\n",
    "    art_up = yasa.hypno_upsample_to_data(art_std, 1, data, target_fs)\n",
    "    data[art_up] = 0\n",
    "    logger.debug(\"FINISHED: Remove artifacts.\")\n",
    "        \n",
    "    data -= data.mean()\n",
    "    return data\n",
    "\n",
    "def get_start_end(hypno: np.ndarray, sleep_state_id: int):\n",
    "    \"\"\"Convert sleep states into lists of start and end time indices.\"\"\"\n",
    "    seq = get_sequences(np.where(hypno == sleep_state_id)[0])\n",
    "    start = []\n",
    "    end = []\n",
    "    for s, e in seq:\n",
    "        start.append(s)\n",
    "        end.append(e)\n",
    "    return (start, end)\n",
    "\n",
    "def _detect_troughs(signal, thr):\n",
    "    lidx  = np.where(signal[0:-2] > signal[1:-1])[0]\n",
    "    ridx  = np.where(signal[1:-1] <= signal[2:])[0]\n",
    "    thidx = np.where(signal[1:-1] < thr)[0]\n",
    "    sidx = np.intersect1d(lidx, np.intersect1d(ridx, thidx))+1\n",
    "    return sidx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of loaded recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbd_cnt = 0\n",
    "rgs_cnt = 0\n",
    "os_cnt = 0\n",
    "\n",
    "# Count recordings belonging to CBD dataset\n",
    "for name in mapped_datasets:\n",
    "    metadata = get_metadata(name)\n",
    "    if metadata['treatment'] == 0 or metadata['treatment'] == 1:\n",
    "        cbd_cnt += 1\n",
    "    elif metadata['treatment'] == 2 or metadata['treatment'] == 3:\n",
    "        rgs_cnt += 1\n",
    "    elif metadata['treatment'] == 4:\n",
    "        os_cnt += 1\n",
    "\n",
    "assert cbd_cnt == 170\n",
    "assert rgs_cnt == 159\n",
    "assert os_cnt == 210"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop through the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(mapped_datasets) as mapped_tqdm:\n",
    "    for name in mapped_tqdm:\n",
    "        metadata = get_metadata(name)\n",
    "        mapped_tqdm.set_postfix_str(name)\n",
    "        states_fname, hpc_fname, pfc_fname = mapped_datasets[name]\n",
    "        logger.debug(\"Loading: {0}\".format(name))\n",
    "\n",
    "        if metadata[\"treatment\"] == 0 or metadata[\"treatment\"] == 1:\n",
    "            n_down = n_down_cbd\n",
    "        elif metadata[\"treatment\"] == 2 or metadata[\"treatment\"] == 3:\n",
    "            n_down = n_down_rgs\n",
    "        elif metadata[\"treatment\"] == 4:\n",
    "            n_down = n_down_os\n",
    "        \n",
    "        # Load the LFP data\n",
    "        lfpHPC = loadmat(hpc_fname)['HPC'].flatten()\n",
    "        lfpPFC = loadmat(pfc_fname)['PFC'].flatten()\n",
    "\n",
    "        # Load the states\n",
    "        hypno = loadmat(states_fname)['states'].flatten()\n",
    "        \n",
    "        # Skip if no REM epoch is detected\n",
    "        if(not (np.any(hypno == 5))):\n",
    "            logger.debug(\"No REM detected. Skipping.\")\n",
    "            continue\n",
    "        elif(np.sum(np.diff(get_sequences(np.where(hypno == 5)[0]))) < 10):\n",
    "            logger.debug(\"No REM longer than 10s. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Create Pynapple IntervalSet        \n",
    "        start, end = get_start_end(hypno=hypno, sleep_state_id=5)\n",
    "        rem_interval = nap.IntervalSet(start=start, end=end)\n",
    "        \n",
    "        # Create TsdFrame for HPC and PFC signals\n",
    "        fs = n_down*targetFs\n",
    "        t = np.arange(0, len(lfpHPC)/fs, 1/fs)\n",
    "        lfp = nap.TsdFrame(t=t, d=np.vstack([lfpHPC, lfpPFC]).T, columns=['HPC', 'PFC'])\n",
    "        \n",
    "        # Detect phasic intervals\n",
    "        lfpHPC_down = preprocess(lfpHPC, n_down)\n",
    "        phREM = detect_phasic(lfpHPC_down, hypno, targetFs)\n",
    "        \n",
    "        # Create phasic REM IntervalSet\n",
    "        start, end = [], []\n",
    "        for rem_idx in phREM:\n",
    "            for s, e in phREM[rem_idx]:\n",
    "                start.append(s/targetFs)\n",
    "                end.append(e/targetFs)\n",
    "        phasic_interval = nap.IntervalSet(start, end)\n",
    "\n",
    "        tonic_interval = rem_interval.set_diff(phasic_interval)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23139/1249661457.py:21: UserWarning: Some epochs have no duration\n",
      "  rem_interval = nap.IntervalSet(start=start, end=end)\n"
     ]
    }
   ],
   "source": [
    "hpc_fname = mapped_datasets['Rat5_SD8_HC_0_posttrial4'][1]\n",
    "pfc_fname = mapped_datasets['Rat5_SD8_HC_0_posttrial4'][2]\n",
    "hypno = mapped_datasets['Rat5_SD8_HC_0_posttrial4'][0]\n",
    "\n",
    "# Load the LFP data\n",
    "lfpHPC = loadmat(hpc_fname)['HPC'].flatten()\n",
    "lfpPFC = loadmat(pfc_fname)['PFC'].flatten()\n",
    "\n",
    "# Load the states\n",
    "hypno = loadmat(hypno)['states'].flatten()\n",
    "\n",
    "# Skip if no REM epoch is detected\n",
    "if(not (np.any(hypno == 5))):\n",
    "    print(\"No REM detected. Skipping.\")\n",
    "elif(np.sum(np.diff(get_sequences(np.where(hypno == 5)[0]))) < 10):\n",
    "    logger.debug(\"No REM longer than 10s. Skipping.\")\n",
    "    print(np.sum(np.diff(get_sequences(np.where(hypno == 5)[0]))))\n",
    "\n",
    "# Create Pynapple IntervalSet        \n",
    "start, end = get_start_end(hypno=hypno, sleep_state_id=5)\n",
    "rem_interval = nap.IntervalSet(start=start, end=end)\n",
    "\n",
    "# Create TsdFrame for HPC and PFC signals\n",
    "fs = int(n_down*targetFs)\n",
    "t = np.arange(0, len(lfpHPC)/fs, 1/fs)\n",
    "lfp = nap.TsdFrame(t=t, d=np.vstack([lfpHPC, lfpPFC]).T, columns=['HPC', 'PFC'])\n",
    "\n",
    "# Detect phasic intervals\n",
    "lfpHPC_down = preprocess(lfpHPC, n_down)\n",
    "phREM = detect_phasic(lfpHPC_down, hypno, targetFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the HPC and PFC signals during phasic REM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp.restrict(phasic_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrem_hpc = [lfp[\"HPC\"].restrict(phasic_interval[i]).to_numpy() for i in range(len(phasic_interval))]\n",
    "tonic_hpc = [lfp[\"HPC\"].restrict(tonic_interval[i]).to_numpy() for i in range(len(tonic_interval))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(name+'_phasic', *phrem_hpc)\n",
    "np.savez(name+'_tonic', *tonic_hpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('Rat5_SD8_HC_0_posttrial3_phasic.npz')\n",
    "phrem = [data[key] for key in data]\n",
    "phrem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access HPC and PFC signals during tonic REM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp.restrict(tonic_interval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
